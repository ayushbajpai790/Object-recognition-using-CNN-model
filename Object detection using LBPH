#train the model
import cv2
import numpy as np
import os
from os import listdir
from os.path import isfile, join
import pyttsx3
# Get the training data we previously made
data_path = './images/'
onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]

# Create arrays for training data and labels
Training_Data, Labels = [], []

# Open training images in our datapath
# Create a numpy array for training data
for i, files in enumerate(onlyfiles):
    image_path = data_path + onlyfiles[i]
    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    Training_Data.append(np.asarray(images, dtype=np.uint8))
    Labels.append(i)
 
# Create a numpy array for both training data and labels
Labels = np.asarray(Labels, dtype=np.int32)

# Initialize facial recognizer
# model = cv2.face.createLBPHFaceRecognizer()
# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()
# pip install opencv-contrib-python
# model = cv2.createLBPHFaceRecognizer()

model  = cv2.face_LBPHFaceRecognizer.create()
# Let's train our model 
model.train(np.asarray(Training_Data), np.asarray(Labels))
#saving our created model in a file
model.save('./ayush4.h5')
pyttsx3.speak("Model trained sucessefully,let's go ahead")
print("success")
import cv2
model  = cv2.face_LBPHFaceRecognizer.create()
model.read('./ayush4.h5') # load the model
cam = cv2.VideoCapture('car chasee.mp4')
count = 0
while True:
    ret, frame = cam.read()
    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
    result = model.predict(gray)
    if result[1] < 500:
            confidence = int( 100 * (1 - (result[1])/400) )
    if confidence >= 80:
        count=count+1
    if count == 100 :
        cv2.imwrite("photo.jpeg",frame)
        print("car detected")
        break
    else :
        print("no car")
cv2.imshow("photo.jpeg",frame)
cv2.waitKey() 
cv2.destroyAllWindows()
pic = cv2.imread('photo.jpeg',cv2.IMREAD_COLOR)
pic = cv2.resize(pic,(500,600))
gray = cv2.cvtColor(pic,cv2.COLOR_BGR2GRAY)  
gray = cv2.bilateralFilter(gray,13,15,15) # remove unwnated things =noise
edged = cv2.Canny(gray,30,200)
import cv2
import imutils
import numpy as np
import pytesseract
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

img = cv2.imread('Cars163.png',cv2.IMREAD_COLOR)
img = cv2.resize(img, (500,600) )
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) 
edged = cv2.Canny(gray, 30, 200) 
contours = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
contours = imutils.grab_contours(contours)
contours = sorted(contours, key = cv2.contourArea, reverse = True)[:10]
screenCnt = None
for c in contours:
    peri = cv2.arcLength(c, True)
    approx = cv2.approxPolyDP(c, 0.018 * peri, True)
    if len(approx) == 4:
        screenCnt = approx
        break

if screenCnt is None:
    detected = 0
    print ("No contour detected")
else:
    detected = 1
    
if detected == 1:
    cv2.drawContours(img, [screenCnt], -1, (0, 0, 255), 3)

mask = np.zeros(gray.shape,np.uint8)
new_image = cv2.drawContours(mask,[screenCnt],0,255,-1,)
new_image = cv2.bitwise_and(img,img,mask=mask)

(x, y) = np.where(mask == 255)
(topx, topy) = (np.min(x), np.min(y))
(bottomx, bottomy) = (np.max(x), np.max(y))
Cropped = gray[topx:bottomx+1, topy:bottomy+1] 
text = pytesseract.image_to_string(Cropped,config='--psm 11')
print("License Plate Recognition\n")
print("Detected license plate Number is:",text)
